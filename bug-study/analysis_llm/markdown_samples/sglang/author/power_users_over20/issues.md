# power_users_over20 - issues

**Total Issues**: 30
**Generated**: 2025-07-23 11:45:14

## Summary Statistics

- Open Issues: 4
- Closed Issues: 26

### Label Distribution

- good first issue: 9 issues
- help wanted: 5 issues
- high priority: 5 issues
- performance: 3 issues
- documentation: 3 issues
- inactive: 3 issues
- enhancement: 2 issues
- backlog: 2 issues
- collaboration: 2 issues
- bug: 1 issues

---

## Issue #N/A: [Feature] integrate nccl 2.27 with pynccl

**Link**: https://github.com/sgl-project/sglang/issues/7010
**State**: open
**Created**: 2025-06-09T17:55:18+00:00
**Comments**: 1

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

as titled

### Related resources

_No response_

---

## Issue #N/A: [PD Bug]  Decode  RuntimeError: no running event loop

**Link**: https://github.com/sgl-project/sglang/issues/7771
**State**: closed
**Created**: 2025-07-04T08:06:43+00:00
**Closed**: 2025-07-05T05:36:57+00:00
**Comments**: 1

### Description

### Checklist

- [x] 1. I have searched related issues but cannot get the expected help.
- [x] 2. The bug has not been fixed in the latest version.
- [x] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [x] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 5. Please use English, otherwise it will be closed.

### Describe the bug

<img width="1246" alt="Image" src="https://github.com/user-attachments/assets/2b7e2e76-ba7b-4cd1-bbf7-0539dff515e0" />

### Reproduction

1. benchmarking
2. restart decode node
3. observe decode log

### Environment

h20 pd

---

## Issue #N/A: [Feature] support ngram

**Link**: https://github.com/sgl-project/sglang/issues/2681
**State**: open
**Created**: 2024-12-31T07:03:24+00:00
**Comments**: 4
**Labels**: enhancement, good first issue, help wanted

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

ref https://github.com/apoorvumang/prompt-lookup-decoding

### Related resources

_No response_

---

## Issue #N/A: [Feature] upgrade flashinfer 0.2.5

**Link**: https://github.com/sgl-project/sglang/issues/5023
**State**: closed
**Created**: 2025-04-03T08:04:23+00:00
**Closed**: 2025-04-30T03:05:57+00:00
**Comments**: 3
**Labels**: good first issue, help wanted

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

as titled

### Related resources

_No response_

---

## Issue #N/A: [Feature] Reorganize Reference Docs

**Link**: https://github.com/sgl-project/sglang/issues/3262
**State**: open
**Created**: 2025-02-02T19:34:09+00:00
**Comments**: 2
**Labels**: good first issue

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

@shuaills Thanks!

### Related resources

_No response_

---

## Issue #N/A: [Feature] adapt fused sigmoid gate for MoE model

**Link**: https://github.com/sgl-project/sglang/issues/2739
**State**: closed
**Created**: 2025-01-05T16:55:21+00:00
**Closed**: 2025-05-25T23:52:20+00:00
**Comments**: 20
**Labels**: good first issue, performance

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

ref https://github.com/NVIDIA/TensorRT-LLM/blob/be1788106245496872d18e702978e59b6bfd50e0/cpp/tensorrt_llm/kernels/mixtureOfExperts/moe_kernels.cu#L232

### Related resources

_No response_

---

## Issue #N/A: [Bug] Link error in SGLang Sampling Docs

**Link**: https://github.com/sgl-project/sglang/issues/2551
**State**: closed
**Created**: 2024-12-23T02:58:24+00:00
**Closed**: 2024-12-26T15:12:28+00:00
**Comments**: 1
**Labels**: documentation

### Description

### Checklist

- [x] 1. I have searched related issues but cannot get the expected help.
- [x] 2. The bug has not been fixed in the latest version.
- [x] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [x] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 5. Please use English, otherwise it will be closed.

### Describe the bug

https://sgl-project.github.io/references/sampling_params.html

This link is an error and I am pondering why it should refer to.


![image](https://github.com/user-attachments/assets/5401ab02-2cbd-476f-bef9-6ac0c7eda58e)



### Reproduction

no such

### Environment

no such

---

## Issue #N/A: [Feature] use vllm as an optional quant library

**Link**: https://github.com/sgl-project/sglang/issues/4546
**State**: closed
**Created**: 2025-03-18T08:09:43+00:00
**Closed**: 2025-05-18T00:20:54+00:00
**Comments**: 1
**Labels**: inactive

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

as titled

In the latest main branch, we have removed the dependency on vLLM for NVIDIA GPU. For large scale online serving, W8A8 Int8 and FP8 should suffice. We may consider supporting other quant methods like Qserve in the future, but using vLLM as an optional quant library is generally adequate. In the upcoming release version, vLLM will not be installed by default. Users who wish to use AWQ or similar quant methods can manually install them.

### Related resources

_No response_

---

## Issue #N/A: [Feature] qwen 3 eagle 3

**Link**: https://github.com/sgl-project/sglang/issues/7617
**State**: closed
**Created**: 2025-06-28T04:44:46+00:00
**Closed**: 2025-07-10T16:33:29+00:00
**Comments**: 3
**Labels**: high priority

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

as titled

### Related resources

_No response_

---

## Issue #N/A: [Tracker] OpenRouter LLM rankings tracking

**Link**: https://github.com/sgl-project/sglang/issues/1152
**State**: closed
**Created**: 2024-08-19T11:41:07+00:00
**Closed**: 2024-09-22T11:07:15+00:00
**Comments**: 2

### Description

### Checklist

- [X] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [X] 2. Please use English, otherwise it will be closed.

### Motivation

This issue is not a bug report or feature request, but just a record of tracking the current popular LLM.

From https://openrouter.ai/rankings `Top this month`, it can be known that, currently in addition to using the closed-source model APIs of OpenAI, Anthropic and Google, users also use open source LLM. The difference between OpenRouter and other rankings is that it better reflects the real usage scenarios and actual conditions of users.

The list shows that the currently mainly used series are [Llama 3](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6), [Llama 3.1](https://huggingface.co/collections/meta-llama/llama-31-669fc079a0c406a149a5738f), [Gemma 2](https://hu

[... truncated for brevity ...]

---

## Issue #N/A: [Bug] vllm updated its get_model function

**Link**: https://github.com/sgl-project/sglang/issues/1183
**State**: closed
**Created**: 2024-08-22T04:47:56+00:00
**Closed**: 2024-08-26T09:03:16+00:00
**Comments**: 4

### Description

### Checklist

- [X] 1. I have searched related issues but cannot get the expected help.
- [X] 2. The bug has not been fixed in the latest version.
- [X] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [X] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [X] 5. Please use English, otherwise it will be closed.

### Describe the bug

Previously we used this in our `ModelRunner`:

```
        self.model = get_model(
            model_config=self.vllm_model_config,
            device_config=self.device_config,
            load_config=self.load_config,
            lora_config=None,
            multimodal_config=None,
            parallel_config=None,
 

[... truncated for brevity ...]

---

## Issue #N/A: [Bug] fix code scanning issue

**Link**: https://github.com/sgl-project/sglang/issues/2315
**State**: closed
**Created**: 2024-12-02T13:42:27+00:00
**Closed**: 2025-02-01T00:17:47+00:00
**Comments**: 1
**Labels**: backlog, inactive

### Description

### Checklist

- [ ] 1. I have searched related issues but cannot get the expected help.
- [ ] 2. The bug has not been fixed in the latest version.
- [ ] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [ ] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 5. Please use English, otherwise it will be closed.

### Describe the bug

ref https://github.com/sgl-project/sglang/security/code-scanning

The priority is not high, I will handle it when I have the bandwidth.

### Reproduction

N/A

### Environment

N/A

---

## Issue #N/A: [Bug] Could not post to external IP address

**Link**: https://github.com/sgl-project/sglang/issues/1064
**State**: closed
**Created**: 2024-08-13T00:19:17+00:00
**Closed**: 2024-08-13T04:37:23+00:00
**Comments**: 1

### Description

### Checklist

- [X] 1. I have searched related issues but cannot get the expected help.
- [X] 2. The bug has not been fixed in the latest version.
- [X] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [x] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.

### Describe the bug

I can’t post to an external IP address. Previously when I used `vllm`, I could use this:

```
client = openai.OpenAI(
        base_url=f"http://{MY_IP_ADDRESS}/:{server.port if server.ip != SERVER_IP_UCLA_03 else 5600}/v1",
        api_key="EMPTY",
    )
```

But now I can only post to `127.0.0.1`. So I have to use `ngrok` to map my external IP address to my local host.

### R

[... truncated for brevity ...]

---

## Issue #N/A: [Feature] Integration of TurboMind AWQ and GPTQ

**Link**: https://github.com/sgl-project/sglang/issues/2788
**State**: open
**Created**: 2025-01-08T08:37:01+00:00
**Comments**: 1
**Labels**: good first issue, help wanted

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

The AWQ and GPTQ of TurboMind should be among the best-performing open-source implementations currently available. We plan to integrate them into SGLang, and once the integration is complete, we can consider removing SGLang's dependency on vLLM's AWQ and GPTQ kernel.

During development, we can initially install the wheel https://github.com/InternLM/turbomind/releases/tag/v0.0.1 manually for verification and later add the TurboMind repo as a dependency in [sgl-kernel](https://github.com/sgl-project/sglang/tree/main/sgl-kernel).

ref
https://github.com/InternLM/turbomind

### Related resources

_No response_

---

## Issue #N/A: [Bug] merge_state_v2 issue

**Link**: https://github.com/sgl-project/sglang/issues/5404
**State**: closed
**Created**: 2025-04-15T06:18:14+00:00
**Closed**: 2025-04-15T17:18:48+00:00
**Comments**: 7
**Labels**: bug, high priority

### Description

### Checklist

- [ ] 1. I have searched related issues but cannot get the expected help.
- [ ] 2. The bug has not been fixed in the latest version.
- [ ] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [ ] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 5. Please use English, otherwise it will be closed.

### Describe the bug

@qingquansong @Fridge003 

### Reproduction

N/A

### Environment

N/A

---

## Issue #N/A: [Bug] it seems memory leak in sglang when longtime serving

**Link**: https://github.com/sgl-project/sglang/issues/1358
**State**: closed
**Created**: 2024-09-09T12:12:45+00:00
**Closed**: 2024-09-09T12:14:07+00:00
**Comments**: 4

### Description

### Checklist

- [X] 1. I have searched related issues but cannot get the expected help.
- [X] 2. The bug has not been fixed in the latest version.
- [X] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [X] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [X] 5. Please use English, otherwise it will be closed.

### Describe the bug

128134 memory blocks: 5104.2 KiB
Traceback:
  File "/usr/local/lib/python3.10/dist-packages/zmq/_future.py", line 374
    loaded = load(buf)

### Reproduction

tracemalloc in detokenizer_manager.py

### Environment

llama2-13B A800*1

---

## Issue #N/A: [Feature] Add Dockerfile.dev for development purposes

**Link**: https://github.com/sgl-project/sglang/issues/2060
**State**: closed
**Created**: 2024-11-17T16:23:48+00:00
**Closed**: 2024-12-01T07:27:53+00:00
**Comments**: 1
**Labels**: backlog

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

Add some commonly used command-line tools

### Related resources

_No response_

---

## Issue #N/A: [Bug] TypeError: GroupCoordinator.all_gather() got an unexpected keyword argument 'tensor_list

**Link**: https://github.com/sgl-project/sglang/issues/7417
**State**: closed
**Created**: 2025-06-21T12:14:50+00:00
**Closed**: 2025-06-21T19:03:12+00:00
**Comments**: 1

### Description

### Checklist

- [ ] 1. I have searched related issues but cannot get the expected help.
- [x] 2. The bug has not been fixed in the latest version.
- [ ] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [x] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 5. Please use English, otherwise it will be closed.

### Describe the bug

```bash
[2025-06-21 19:55:30 DP0 TP7] TpModelWorkerClient hit an exception: Traceback (most recent call last):
  File "/usr/local/src/sglang/python/sglang/srt/managers/tp_worker_overlap_thread.py", line 127, in forward_thread_func
    self.forward_thread_func_()
  File "/usr/local/lib/python3.10/site-packages/torch/utils/_contextlib.py", l

[... truncated for brevity ...]

---

## Issue #N/A: [Feature] Change contribution guide

**Link**: https://github.com/sgl-project/sglang/issues/2662
**State**: closed
**Created**: 2024-12-30T07:53:12+00:00
**Closed**: 2025-04-29T16:22:21+00:00
**Comments**: 3
**Labels**: documentation, good first issue

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

https://sgl-project.github.io/references/contributor_guide.html

This has been outdated for long. We need to add guide on:

1. How to run docs CI, build it locally, compile it and clean the output and make PR.
2. How to do unit tests locally and add unit tests to CI.
3. How to write elegant unit test following other tests.
4. How to pre-commit.

### Related resources

_No response_

---

## Issue #N/A: [OAI Server] Invesitgate P99 TTFT issue of oai adapter

**Link**: https://github.com/sgl-project/sglang/issues/7109
**State**: closed
**Created**: 2025-06-12T00:39:24+00:00
**Closed**: 2025-06-17T19:43:18+00:00
**Comments**: 5

### Description

There is an observation of high P99 latency when making requests through the OpenAI-compatible API path (`http_server.py` -> `adapter.py`) under high concurrency, compared to the native `/generate` endpoint. 

The goal is to identify the bottleneck within the `adapter.py` layer.

---

## Issue #N/A: [Bug] The radix cache affects the accuracy of the output results.

**Link**: https://github.com/sgl-project/sglang/issues/4175
**State**: closed
**Created**: 2025-03-07T09:00:36+00:00
**Closed**: 2025-03-07T09:47:07+00:00
**Comments**: 0

### Description

### Checklist

- [x] 1. I have searched related issues but cannot get the expected help.
- [x] 2. The bug has not been fixed in the latest version.
- [x] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [x] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 5. Please use English, otherwise it will be closed.

### Describe the bug

After enabling the radix cache, performing a large number of serial requests will result in a small number of requests being inconsistent with those when the radix cache is not enabled. Is this consistent with expectations?

### Reproduction

Send 1000 requests serially using the llama or mixtral model. Restart the service and close the ra

[... truncated for brevity ...]

---

## Issue #N/A: [OAI Server Refactor] [ChatCompletions & Completions] Add UTs for Tool Call and Reasoning Text Handling

**Link**: https://github.com/sgl-project/sglang/issues/7261
**State**: closed
**Created**: 2025-06-17T04:29:31+00:00
**Closed**: 2025-06-17T04:36:53+00:00
**Comments**: 2

### Description

**Points**: 1-2 days

**Description**: Current the tool call handling and reasoning text logic in [`serving_chat.py`](https://github.com/sgl-project/sglang/blob/70c471a868bf505fadbfe0a041e7637a91db0365/python/sglang/srt/entrypoints/openai/serving_chat.py)

**Deliverables:**
- [ ] Complete tasks below

---

## Issue #N/A: [Feature] integrate flash-attention

**Link**: https://github.com/sgl-project/sglang/issues/4385
**State**: closed
**Created**: 2025-03-13T10:50:36+00:00
**Closed**: 2025-04-22T08:25:20+00:00
**Comments**: 2
**Labels**: high priority

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

similar with https://github.com/sgl-project/sglang/issues/4384

Since SGLang now supports page sizes greater than 1 https://github.com/sgl-project/sglang/pull/4356, we should integrate flash-attention https://github.com/Dao-AILab/flash-attention

### Related resources

_No response_

---

## Issue #N/A: [Feature] support merge_state in sgl-kernel

**Link**: https://github.com/sgl-project/sglang/issues/5361
**State**: closed
**Created**: 2025-04-14T00:56:57+00:00
**Closed**: 2025-04-15T04:32:18+00:00
**Comments**: 3
**Labels**: high priority, collaboration, speculative-decoding

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

I have talked to @deftruth, and he will support it in the sgl-kernel today

### Related resources

_No response_

---

## Issue #N/A: AWQ performance tracking

**Link**: https://github.com/sgl-project/sglang/issues/1505
**State**: closed
**Created**: 2024-09-24T14:33:27+00:00
**Closed**: 2024-11-24T01:20:38+00:00
**Comments**: 2
**Labels**: inactive, performance

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

# Current Situation

## SGLang

```bash
# v0.3.1.post3
pip install --upgrade pip
pip install "sglang[all]"

pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/
```

```
python3 -m sglang.launch_server --model hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4 --disable-radix

python3 bench_serving.py --backend sglang --num-prompts 5000
```

```
============ Serving Benchmark Result ============
Backend:                                 sglang
Traffic request rate:                    inf
Successful requests:                     5000
Benchmark duration (s):                  161.16
Total input tokens:                      1130466
Total generated tokens:                  971613


[... truncated for brevity ...]

---

## Issue #N/A: [Docs] Add docs for running SGLang on AMD

**Link**: https://github.com/sgl-project/sglang/issues/3245
**State**: closed
**Created**: 2025-02-01T00:23:16+00:00
**Closed**: 2025-05-21T15:40:21+00:00
**Comments**: 4
**Labels**: documentation, good first issue, help wanted, amd

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

That has long been waiting, we should add a docs on how to run SGLang on AMD devices.

https://github.com/sgl-project/sglang/issues/3219
https://github.com/sgl-project/sglang/issues/3243
https://github.com/sgl-project/sglang/issues/3200
https://github.com/sgl-project/sglang/pull/3208
https://github.com/sgl-project/sglang/issues/3198

Here is something related. To me, I think we should add a docs on how to:
 
1. configure environment in AMD GPU;
2. how to install sglang;
3. how to run a llama model;
4. how to run deepseek V3 models.

### Related resources

_No response_

---

## Issue #N/A: [Feature] Add Math in our CI

**Link**: https://github.com/sgl-project/sglang/issues/2504
**State**: closed
**Created**: 2024-12-17T22:37:36+00:00
**Closed**: 2024-12-30T06:52:10+00:00
**Comments**: 4
**Labels**: enhancement, good first issue

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

One of my friends told me that SGLang Engine's performance on Math is abnormally a bit lower. We will find this out, benchmarking SGLang and other engines' performance on Math (use GPT-4 to evaluate). And, ultimately, we will add a CI test for Math which runs daily.

### Related resources

No such.

---

## Issue #N/A: [PD Bug]  transfer  exception and deepep timeout

**Link**: https://github.com/sgl-project/sglang/issues/7557
**State**: closed
**Created**: 2025-06-26T08:41:08+00:00
**Closed**: 2025-06-30T11:54:35+00:00
**Comments**: 1

### Description

### Checklist

- [ ] 1. I have searched related issues but cannot get the expected help.
- [ ] 2. The bug has not been fixed in the latest version.
- [ ] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [ ] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 5. Please use English, otherwise it will be closed.

### Describe the bug

<img width="841" alt="Image" src="https://github.com/user-attachments/assets/fe6d7434-ad09-452b-a030-c273da1b3ddd" />

@ShangmingCai 

### Reproduction

prefill H20

p2D4:

```
 python -m sglang.launch_server --model-path /work/models/ --port 30000 --trust-remote --host 0.0.0.0 --disable-radix-cache --init-expert-location /home/aiges/tuned

[... truncated for brevity ...]

---

## Issue #N/A: [OAI Server Refactor] Core Utility Endpoints

**Link**: https://github.com/sgl-project/sglang/issues/7102
**State**: closed
**Created**: 2025-06-11T23:59:58+00:00
**Closed**: 2025-06-17T04:07:48+00:00
**Comments**: 2

### Description

Points: 2-3 days

Description: Implement the core utility endpoints needed by all OpenAI-compatible clients.

Deliverables:

- Implement `/v1/models` endpoint to list available models
- Add engine lifecycle management in the lifespan handler, following `http_server.py` in `python/sglang/srt/http_server.py`
- Add metrics middleware
- Add all openai endpoints, skip implementation for now

Testing:

- Verify proper model listing
- Ensure metrics are correctly exposed

---

## Issue #N/A: [Feature] beat torch compile

**Link**: https://github.com/sgl-project/sglang/issues/4748
**State**: closed
**Created**: 2025-03-25T06:18:28+00:00
**Closed**: 2025-05-26T16:55:12+00:00
**Comments**: 7
**Labels**: good first issue, help wanted, high priority, collaboration, performance

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

as titled

Last year and in the first few months of this year, a significant part of my work focused on removing vLLM dependency. Many reliable teammates joined in this process, and we successfully removed the vLLM dependency on the NVIDIA platform for SGLang. Next, I will co-lead progress on beat torch compile. Past experience shows that torch compile is effective - we just need to write some simple torch ops and let torch compile handle the rest. However, in actual production serving, it is not as smooth as expected - for example, slow startup even with cache enabled, compatibility issues when upgrading torch versions leading to previous features breaking in new versions. We need to profile, benchmark, rewrite th

[... truncated for brevity ...]

---

