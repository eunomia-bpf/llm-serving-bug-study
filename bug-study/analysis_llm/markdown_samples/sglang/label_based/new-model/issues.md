# new-model - issues

**Total Issues**: 19
**Generated**: 2025-07-23 11:45:14

## Summary Statistics

- Open Issues: 16
- Closed Issues: 3

### Label Distribution

- new-model: 19 issues
- good first issue: 8 issues
- high priority: 3 issues
- help wanted: 3 issues
- inactive: 2 issues
- enhancement: 1 issues
- MLLM: 1 issues
- feature: 1 issues

---

## Issue #N/A: [Tracking] Model support

**Link**: https://github.com/sgl-project/sglang/issues/7429
**State**: open
**Created**: 2025-06-21T22:18:10+00:00
**Comments**: 22
**Labels**: good first issue, new-model

### Description

### **[Tracking] Model support**

The goal is to support other model architectures available. Expand the model zoo ðŸŽŠ 

The goal is to implement support for all architectures listed below. Anyone is welcome to take any issue or implement the model below.

If you need help implementing a new model, see https://docs.sglang.ai/supported_models/support_new_models.html

#### Text-only Language Models (Generative)
- [ ] `OPTForCasualLM` (facebook/opt-125m) #7440 
- [ ] `AquilaForCausalLM` (Aquila, Aquila2)
- [ ] `ArcticForCausalLM` (Arctic) #5768
- [ ] `BambaForCausalLM` (Bamba)
- [ ] `BartForConditionalGeneration` (BART)
- [ ] `BloomForCausalLM` (BLOOM, BLOOMZ)
- [ ] `Cohere2ForCasualLM` #4570
- [ ] `DeciLMForCausalLM` (DeciLM)
- [ ] `FalconForCausalLM` (Falcon)
- [ ] `FalconH1ForCausalLM` (Falcon-H1) #6517
- [ ] `FalconMambaForCausalLM` (FalconMamba)
- [ ] `Dots1ForCasualLM` (dots.llm1) #6471
- [ ] `GPT2LMHeadModel` (GPT-2)
- [ ] `GPTBigCodeForCausalLM` (StarCoder, SantaCoder)
- [ ] `GPTJFo

[... truncated for brevity ...]

---

## Issue #N/A: [Feature]  It is hoped that the deployment of the ByteDance-Seed/BAGEL-7B-MoT model can be supported

**Link**: https://github.com/sgl-project/sglang/issues/6724
**State**: open
**Created**: 2025-05-29T03:32:37+00:00
**Comments**: 0
**Labels**: new-model

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

It is hoped that support can be provided for the ByteDance-Seed/BAGEL-7B-MoT model.

### Related resources

_No response_

---

## Issue #N/A: [Feature] Model FalconH1

**Link**: https://github.com/sgl-project/sglang/issues/6517
**State**: open
**Created**: 2025-05-22T05:00:53+00:00
**Comments**: 2
**Labels**: new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

Please support the Falcon H1 model series. Support is already available in vLLM and transformers!

### Related resources

https://falcon-lm.github.io/blog/falcon-h1/
https://github.com/vllm-project/vllm/pull/18406
https://github.com/huggingface/transformers/pull/38249

---

## Issue #N/A: [Feature] Gemma 3n support

**Link**: https://github.com/sgl-project/sglang/issues/6498
**State**: closed
**Created**: 2025-05-21T09:35:34+00:00
**Closed**: 2025-07-01T07:40:13+00:00
**Comments**: 3
**Labels**: high priority, new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

Hello, kindly add support for Gemma 3n model. This model only runs on edge devices. it will be good, if we use this model through sglang framework.

### Related resources

_No response_

---

## Issue #N/A: [Feature] When will the GLM4-32B series be supportedï¼Ÿ

**Link**: https://github.com/sgl-project/sglang/issues/6374
**State**: closed
**Created**: 2025-05-17T14:01:12+00:00
**Closed**: 2025-06-26T01:33:13+00:00
**Comments**: 4
**Labels**: good first issue, new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

When the GLM4-32B family will be supported in sglang? And which parser will be used in tool calls

### Related resources

_No response_

---

## Issue #N/A: [Feature] GLM-4-0414 support?

**Link**: https://github.com/sgl-project/sglang/issues/5832
**State**: closed
**Created**: 2025-04-28T11:26:34+00:00
**Closed**: 2025-06-21T22:10:15+00:00
**Comments**: 2
**Labels**: new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

GLM-4-0414 support is on [VLLM](https://github.com/vllm-project/vllm/pull/16338), does it hard to include support of GLM-4-0414 on sglang.

It's currently the best no-reason 32b model for some tasks such as one-shoot code generations.

### Related resources

_No response_

---

## Issue #N/A: [Feature]  Support Gemma 3 QAT models

**Link**: https://github.com/sgl-project/sglang/issues/5591
**State**: open
**Created**: 2025-04-21T05:53:29+00:00
**Comments**: 1
**Labels**: high priority, new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

Hello SGLang team,

Could you please add support for the quantization-aware training models of Google's Gemma 3? Thanks!

### Related resources

_No response_

---

## Issue #N/A: [Bug] ValueError: Model architectures ['Glm4ForCausalLM'] are not supported for now.

**Link**: https://github.com/sgl-project/sglang/issues/5441
**State**: open
**Created**: 2025-04-16T01:49:12+00:00
**Comments**: 3
**Labels**: new-model

### Description

### Checklist

- [x] 1. I have searched related issues but cannot get the expected help.
- [x] 2. The bug has not been fixed in the latest version.
- [x] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [x] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 5. Please use English, otherwise it will be closed.

### Describe the bug

ValueError: Model architectures ['Glm4ForCausalLM'] are not supported for now. 

```
ValueError: Model architectures ['Glm4ForCausalLM'] are not supported for now. Supported architectures: dict_keys(['BaichuanForCausalLM', 'ChatGLMModel', 'CLIPModel', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'DbrxForCausalLM', 'DeepseekForCausalLM', 'Mul

[... truncated for brevity ...]

---

## Issue #N/A: [Feature] Ovis2 surport

**Link**: https://github.com/sgl-project/sglang/issues/5018
**State**: open
**Created**: 2025-04-03T02:40:00+00:00
**Comments**: 3
**Labels**: new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

The Ovis2 series multimodal model performance is very good, and the gptq int4 version has been released recently, with a wide range of applications.
[Ovis2-34B](https://huggingface.co/AIDC-AI/Ovis2-34B)ï¼ŒOvis2-34Bæ€§èƒ½è¶…è¿‡qwen2.5-vl-72b.
The vllm project is expected to support Ovis2 soon. [vllm Ovis2 surport](https://github.com/vllm-project/vllm/pull/15826)

### Related resources

_No response_

---

## Issue #N/A: [Feature] Skywork-R1V support

**Link**: https://github.com/sgl-project/sglang/issues/4692
**State**: open
**Created**: 2025-03-23T06:57:56+00:00
**Comments**: 3
**Labels**: new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

 Skywork R1V, the first industry open-sourced multimodal reasoning model with advanced visual chain-of-thought capabilities, pushing the boundaries of AI-driven vision and logical inference!

### Related resources

https://github.com/SkyworkAI/Skywork-R1V

---

## Issue #N/A: [Bug] Testing new Llama-3_3-Nemotron-Super-49B-v1 by Nvidia: "Model architectures ['DeciLMForCausalLM'] are not supported for now."

**Link**: https://github.com/sgl-project/sglang/issues/4689
**State**: open
**Created**: 2025-03-23T05:40:20+00:00
**Comments**: 14
**Labels**: enhancement, good first issue, help wanted, new-model

### Description

### Checklist

- [x] 1. I have searched related issues but cannot get the expected help.
- [x] 2. The bug has not been fixed in the latest version.
- [ ] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [ ] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 5. Please use English, otherwise it will be closed.

### Describe the bug

I tried to run on SGLang Llama-3_3-Nemotron-Super-49B-v1 recently announced by Nvidia.

It seems not to be yet supported by SGLang since `DeciLMForCausalLM`is not yet accepted by SGLang. See below.

Can you add corresponding support?

```
Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-

[... truncated for brevity ...]

---

## Issue #N/A: [Feature] Support Cohere Command-A (Cohere2ForCausalLM arch)

**Link**: https://github.com/sgl-project/sglang/issues/4570
**State**: open
**Created**: 2025-03-19T07:08:58+00:00
**Comments**: 3
**Labels**: new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

It would be great to support this new model: https://huggingface.co/CohereForAI/c4ai-command-a-03-2025

What's special about this model is that they use an unusual architecture where some layers require sliding windows and some don't:

> The model features three layers with sliding window attention (window size 4096) and RoPE for efficient local context modeling and relative positional encoding. A fourth layer uses global attention without positional embeddings, enabling unrestricted token interactions across the entire sequence.

I've found a `Cohere2ForCausalLM` in this project already but it appears to be a stub that is not implemented yet: https://github.com/sgl-project/sglang/blob/90532b762777302cd46a9a38b6675

[... truncated for brevity ...]

---

## Issue #N/A: [Feature] Can you support the VLA series models? For example, openVLA.

**Link**: https://github.com/sgl-project/sglang/issues/4414
**State**: open
**Created**: 2025-03-14T07:00:28+00:00
**Comments**: 1
**Labels**: inactive, new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

The documentation does not support the VLA series large models. Can you support the VLA series models?

### Related resources

_No response_

---

## Issue #N/A: [Bug] granite-vision-3.2-2b failing on sglang with "LlavaNextForConditionalGeneration not supported"

**Link**: https://github.com/sgl-project/sglang/issues/4062
**State**: open
**Created**: 2025-03-04T10:05:44+00:00
**Comments**: 3
**Labels**: inactive, MLLM, new-model

### Description

### Checklist

- [x] 1. I have searched related issues but cannot get the expected help.
- [x] 2. The bug has not been fixed in the latest version.
- [ ] 3. Please note that if the bug-related issue you submitted lacks corresponding environment info and a minimal reproducible demo, it will be challenging for us to reproduce and resolve the issue, reducing the likelihood of receiving feedback.
- [ ] 4. If the issue you raised is not a bug but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 5. Please use English, otherwise it will be closed.

### Describe the bug

Hi,

I have successfully run the 3.1 versions of granite models on SGLang project (https://github.com/sgl-project/sglang)

I am now trying to run granite-vision-3.2-2b  

But it fails, with the messages below: in particular `Model architectures ['LlavaNextForConditionalGeneration'] are not supported for now? `

will IBM work with SGLang pr

[... truncated for brevity ...]

---

## Issue #N/A: [Feature] facebook/contriever support requring

**Link**: https://github.com/sgl-project/sglang/issues/3720
**State**: open
**Created**: 2025-02-20T03:55:48+00:00
**Comments**: 8
**Labels**: good first issue, help wanted, new-model

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

I guess facebook/contriever somehow is a popular embedding model so if SGLang supports it, will be very cool.

But I guess it may be time-consuming to support a model that is not llama-structure, but it is indeed popular in RAG setting.

### Related resources

_No response_

---

## Issue #N/A: [Feature] support MiniMax

**Link**: https://github.com/sgl-project/sglang/issues/2898
**State**: open
**Created**: 2025-01-15T06:36:10+00:00
**Comments**: 5
**Labels**: good first issue, help wanted, high priority, new-model

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

ref https://github.com/MiniMax-AI/MiniMax-01

### Related resources

_No response_

---

## Issue #N/A: [Feature] Jamba 1.5 Support PLS

**Link**: https://github.com/sgl-project/sglang/issues/1190
**State**: open
**Created**: 2024-08-23T09:49:47+00:00
**Comments**: 2
**Labels**: good first issue, new-model

### Description

### Checklist

- [x] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [x] 2. Please use English, otherwise it will be closed.

### Motivation

First SOTA ssm based model, vllm currently supports it but there is some parallel work in vllm to optimise it aswell
- https://github.com/vllm-project/vllm/pull/7428
- https://github.com/vllm-project/vllm/pull/7651

https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251

### Related resources

vllm implementation
https://github.com/vllm-project/vllm/pull/4115

---

## Issue #N/A: [Feature] Support TRI-ML/prismatic-vlms

**Link**: https://github.com/sgl-project/sglang/issues/1129
**State**: open
**Created**: 2024-08-16T18:15:10+00:00
**Comments**: 2
**Labels**: good first issue, feature, new-model

### Description

### Checklist

- [X] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [X] 2. Please use English, otherwise it will be closed.

### Motivation

I'm trying to speed up inference for new VLM models on huggingface: https://huggingface.co/TRI-ML/prismatic-vlms/tree/main. I'm wondering if there are additional documentation on how to adapt new models? 

### Related resources

The model I'm trying to adapt is detailed here: https://arxiv.org/pdf/2402.07865. 

---

## Issue #N/A: [Feature] Do we have any plan for supporting Phi3V?

**Link**: https://github.com/sgl-project/sglang/issues/1108
**State**: open
**Created**: 2024-08-15T05:03:47+00:00
**Comments**: 2
**Labels**: good first issue, new-model

### Description

### Checklist

- [ ] 1. If the issue you raised is not a feature but a question, please raise a discussion at https://github.com/sgl-project/sglang/discussions/new/choose Otherwise, it will be closed.
- [ ] 2. Please use English, otherwise it will be closed.

### Motivation

Do we have any plan for supporting Phi3V?

### Related resources

_No response_

---

