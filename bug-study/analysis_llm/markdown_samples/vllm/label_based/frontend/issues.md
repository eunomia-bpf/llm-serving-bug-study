# frontend - issues

**Total Issues**: 1
**Generated**: 2025-07-23 11:45:14

## Summary Statistics

- Open Issues: 0
- Closed Issues: 1

### Label Distribution

- good first issue: 1 issues
- feature request: 1 issues
- frontend: 1 issues

---

## Issue #N/A: [Feature]: OpenAI Response API

**Link**: https://github.com/vllm-project/vllm/issues/15237
**State**: closed
**Created**: 2025-03-20T17:13:04+00:00
**Closed**: 2025-03-20T22:52:05+00:00
**Comments**: 5
**Labels**: good first issue, feature request, frontend

### Description

### ðŸš€ The feature, motivation and pitch

I come across this https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses&example=chain-of-thought#streaming wrt to their new Response API, so we probably also want to add support in vLLM.

### Alternatives

_No response_

### Additional context

_No response_

### Before submitting a new issue...

- [x] Make sure you already searched for relevant issues, and asked the chatbot living at the bottom right corner of the [documentation page](https://docs.vllm.ai/en/latest/), which can answer lots of frequently asked questions.

---

