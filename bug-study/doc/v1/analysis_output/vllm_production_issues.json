{
  "name": "vLLM",
  "total_production_issues": 3612,
  "bug_issues": 2225,
  "categories": {
    "concurrency": 396,
    "gpu": 430,
    "api": 497,
    "model": 457,
    "crash": 96,
    "scaling": 184,
    "performance": 155,
    "memory": 44
  },
  "samples": {
    "concurrency": [
      {
        "number": 21175,
        "title": "[Bug]: Wrongly reuse KV, for V1 PD disaggregation with multimodal input",
        "state": "open",
        "created_at": "2025-07-18T10:04:41Z",
        "labels": [
          "bug"
        ],
        "errors": []
      },
      {
        "number": 21170,
        "title": "[Bug]: How to Resolve KVC Transmission Timeout",
        "state": "open",
        "created_at": "2025-07-18T09:27:05Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "al scenarios. For instance, if the kv_cache for storing a request times out and no exception handling is performed on the request, it could result in the request being unable to proceed with inference and the block being unable to be released.",
          "handling for these operations."
        ]
      },
      {
        "number": 21165,
        "title": "[Bug]: Mistral crashes on tool_calls with empty description",
        "state": "open",
        "created_at": "2025-07-18T08:47:33Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "is returned:",
          "\",\"message\":\"1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type 1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}"
        ]
      },
      {
        "number": 21156,
        "title": "[Bug]: When making a streaming request, the 9-digit integer in the function call result will be truncated to 6 digits",
        "state": "open",
        "created_at": "2025-07-18T02:43:10Z",
        "labels": [
          "bug"
        ],
        "errors": []
      },
      {
        "number": 21148,
        "title": "[Bug]: Server hang with google/gemma-3-27b-it and structured decoding",
        "state": "open",
        "created_at": "2025-07-17T22:53:42Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "07-17 22:03:54 [backend_xgrammar.py:167] Failed to advance FSM for request chatcmpl-78eca22187e24416a39e4c12c73dad75 for tokens 0. Please file an issue.",
          "message"
        ]
      }
    ],
    "gpu": [
      {
        "number": 21175,
        "title": "[Bug]: Wrongly reuse KV, for V1 PD disaggregation with multimodal input",
        "state": "open",
        "created_at": "2025-07-18T10:04:41Z",
        "labels": [
          "bug"
        ],
        "errors": []
      },
      {
        "number": 21165,
        "title": "[Bug]: Mistral crashes on tool_calls with empty description",
        "state": "open",
        "created_at": "2025-07-18T08:47:33Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "is returned:",
          "\",\"message\":\"1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type 1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}"
        ]
      },
      {
        "number": 21160,
        "title": "[Performance]: `model_weights` generator invoked out of Model loading in EAGLE series models.",
        "state": "open",
        "created_at": "2025-07-18T06:40:37Z",
        "labels": [
          "performance"
        ],
        "errors": []
      },
      {
        "number": 21156,
        "title": "[Bug]: When making a streaming request, the 9-digit integer in the function call result will be truncated to 6 digits",
        "state": "open",
        "created_at": "2025-07-18T02:43:10Z",
        "labels": [
          "bug"
        ],
        "errors": []
      },
      {
        "number": 21148,
        "title": "[Bug]: Server hang with google/gemma-3-27b-it and structured decoding",
        "state": "open",
        "created_at": "2025-07-17T22:53:42Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "07-17 22:03:54 [backend_xgrammar.py:167] Failed to advance FSM for request chatcmpl-78eca22187e24416a39e4c12c73dad75 for tokens 0. Please file an issue.",
          "message"
        ]
      }
    ],
    "api": [
      {
        "number": 21175,
        "title": "[Bug]: Wrongly reuse KV, for V1 PD disaggregation with multimodal input",
        "state": "open",
        "created_at": "2025-07-18T10:04:41Z",
        "labels": [
          "bug"
        ],
        "errors": []
      },
      {
        "number": 21170,
        "title": "[Bug]: How to Resolve KVC Transmission Timeout",
        "state": "open",
        "created_at": "2025-07-18T09:27:05Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "al scenarios. For instance, if the kv_cache for storing a request times out and no exception handling is performed on the request, it could result in the request being unable to proceed with inference and the block being unable to be released.",
          "handling for these operations."
        ]
      },
      {
        "number": 21165,
        "title": "[Bug]: Mistral crashes on tool_calls with empty description",
        "state": "open",
        "created_at": "2025-07-18T08:47:33Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "is returned:",
          "\",\"message\":\"1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type 1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}"
        ]
      },
      {
        "number": 21160,
        "title": "[Performance]: `model_weights` generator invoked out of Model loading in EAGLE series models.",
        "state": "open",
        "created_at": "2025-07-18T06:40:37Z",
        "labels": [
          "performance"
        ],
        "errors": []
      },
      {
        "number": 21156,
        "title": "[Bug]: When making a streaming request, the 9-digit integer in the function call result will be truncated to 6 digits",
        "state": "open",
        "created_at": "2025-07-18T02:43:10Z",
        "labels": [
          "bug"
        ],
        "errors": []
      }
    ],
    "model": [
      {
        "number": 21175,
        "title": "[Bug]: Wrongly reuse KV, for V1 PD disaggregation with multimodal input",
        "state": "open",
        "created_at": "2025-07-18T10:04:41Z",
        "labels": [
          "bug"
        ],
        "errors": []
      },
      {
        "number": 21170,
        "title": "[Bug]: How to Resolve KVC Transmission Timeout",
        "state": "open",
        "created_at": "2025-07-18T09:27:05Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "al scenarios. For instance, if the kv_cache for storing a request times out and no exception handling is performed on the request, it could result in the request being unable to proceed with inference and the block being unable to be released.",
          "handling for these operations."
        ]
      },
      {
        "number": 21165,
        "title": "[Bug]: Mistral crashes on tool_calls with empty description",
        "state": "open",
        "created_at": "2025-07-18T08:47:33Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "is returned:",
          "\",\"message\":\"1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type 1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}"
        ]
      },
      {
        "number": 21160,
        "title": "[Performance]: `model_weights` generator invoked out of Model loading in EAGLE series models.",
        "state": "open",
        "created_at": "2025-07-18T06:40:37Z",
        "labels": [
          "performance"
        ],
        "errors": []
      },
      {
        "number": 21156,
        "title": "[Bug]: When making a streaming request, the 9-digit integer in the function call result will be truncated to 6 digits",
        "state": "open",
        "created_at": "2025-07-18T02:43:10Z",
        "labels": [
          "bug"
        ],
        "errors": []
      }
    ],
    "crash": [
      {
        "number": 21170,
        "title": "[Bug]: How to Resolve KVC Transmission Timeout",
        "state": "open",
        "created_at": "2025-07-18T09:27:05Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "al scenarios. For instance, if the kv_cache for storing a request times out and no exception handling is performed on the request, it could result in the request being unable to proceed with inference and the block being unable to be released.",
          "handling for these operations."
        ]
      },
      {
        "number": 21165,
        "title": "[Bug]: Mistral crashes on tool_calls with empty description",
        "state": "open",
        "created_at": "2025-07-18T08:47:33Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "is returned:",
          "\",\"message\":\"1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type 1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}"
        ]
      },
      {
        "number": 21148,
        "title": "[Bug]: Server hang with google/gemma-3-27b-it and structured decoding",
        "state": "open",
        "created_at": "2025-07-17T22:53:42Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "07-17 22:03:54 [backend_xgrammar.py:167] Failed to advance FSM for request chatcmpl-78eca22187e24416a39e4c12c73dad75 for tokens 0. Please file an issue.",
          "message"
        ]
      },
      {
        "number": 21122,
        "title": "[Bug]: Issue running mistralai/Magistral-Small-2506 on NVIDIA hardware",
        "state": "open",
        "created_at": "2025-07-17T15:02:36Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "not a string exception when running vLLM (v0.9.2) with the mistralai/Magistral-Small-2506 model on NVIDIA H200 hardeware.",
          "```"
        ]
      },
      {
        "number": 21112,
        "title": "[Bug]: TypeError: Object of type <class 'function'> is not serializable",
        "state": "closed",
        "created_at": "2025-07-17T10:01:47Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "(TypeError): ray::vLLM.collective_rpc() (pid=755, ip=172.31.202.67, actor_id=9f52d0baa7a6cc1d4a34e13805000000, repr=<vllm.vLLM object at 0x7fe251cc9790>)",
          "(f\"Object of type {type(obj)} is not serializable\""
        ]
      }
    ],
    "scaling": [
      {
        "number": 21165,
        "title": "[Bug]: Mistral crashes on tool_calls with empty description",
        "state": "open",
        "created_at": "2025-07-18T08:47:33Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "is returned:",
          "\",\"message\":\"1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type 1 validation error for ChatCompletionRequest\\ntools.0.function.description\\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\",\"type\":\"BadRequestError\",\"param\":null,\"code\":400}"
        ]
      },
      {
        "number": 21134,
        "title": "[Bug]: Empty VllmConfig when calling `get_current_vllm_config`, causing VllmConfig `__post__init__` to fail",
        "state": "open",
        "created_at": "2025-07-17T18:46:34Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "traceback.print_stack()\n```"
        ]
      },
      {
        "number": 21120,
        "title": "[Bug]: vllm serve THUDM/GLM-4.1V-9B-Thinking --limit-mm-per-prompt image =32  \uff1a ValueError: `limit_mm_per_prompt` is only supported for multimodal models.",
        "state": "closed",
        "created_at": "2025-07-17T12:43:04Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "(\"`limit_mm_per_prompt` is only supported for \"",
          "`limit_mm_per_prompt` is only supported for multimodal models."
        ]
      },
      {
        "number": 21112,
        "title": "[Bug]: TypeError: Object of type <class 'function'> is not serializable",
        "state": "closed",
        "created_at": "2025-07-17T10:01:47Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "(TypeError): ray::vLLM.collective_rpc() (pid=755, ip=172.31.202.67, actor_id=9f52d0baa7a6cc1d4a34e13805000000, repr=<vllm.vLLM object at 0x7fe251cc9790>)",
          "(f\"Object of type {type(obj)} is not serializable\""
        ]
      },
      {
        "number": 21110,
        "title": "[Bug]: FP8 Attention on H100 - CUDA error: an illegal memory access was encountered",
        "state": "open",
        "created_at": "2025-07-17T09:36:20Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "an illegal memory access was encountered` and the server crashes. I am unable to share an explicit reproducible example currently, but will update when I am able to extract a specific combination of model+config+prompt that fails.",
          "trace</summary>"
        ]
      }
    ],
    "performance": [
      {
        "number": 21160,
        "title": "[Performance]: `model_weights` generator invoked out of Model loading in EAGLE series models.",
        "state": "open",
        "created_at": "2025-07-18T06:40:37Z",
        "labels": [
          "performance"
        ],
        "errors": []
      },
      {
        "number": 21148,
        "title": "[Bug]: Server hang with google/gemma-3-27b-it and structured decoding",
        "state": "open",
        "created_at": "2025-07-17T22:53:42Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "07-17 22:03:54 [backend_xgrammar.py:167] Failed to advance FSM for request chatcmpl-78eca22187e24416a39e4c12c73dad75 for tokens 0. Please file an issue.",
          "message"
        ]
      },
      {
        "number": 21141,
        "title": "[Performance]: Opportunities to speed up BlockPool processing",
        "state": "open",
        "created_at": "2025-07-17T20:59:45Z",
        "labels": [
          "performance"
        ],
        "errors": []
      },
      {
        "number": 21140,
        "title": "[Performance]: Reduce overhead of FreeKVCacheBlockQueue",
        "state": "closed",
        "created_at": "2025-07-17T20:56:09Z",
        "labels": [
          "performance"
        ],
        "errors": []
      },
      {
        "number": 21122,
        "title": "[Bug]: Issue running mistralai/Magistral-Small-2506 on NVIDIA hardware",
        "state": "open",
        "created_at": "2025-07-17T15:02:36Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "not a string exception when running vLLM (v0.9.2) with the mistralai/Magistral-Small-2506 model on NVIDIA H200 hardeware.",
          "```"
        ]
      }
    ],
    "memory": [
      {
        "number": 21073,
        "title": "[Bug]: vLLM doesn't release memory on deletion of the LLM runner with VLLM_ENABLE_V1_MULTIPROCESSING=0",
        "state": "open",
        "created_at": "2025-07-16T19:08:49Z",
        "labels": [
          "bug"
        ],
        "errors": []
      },
      {
        "number": 21027,
        "title": "[Performance]: The GPU memory usage of vllm v0.9.2 is significantly higher than that of v0.9.1. Why is this? How can it be improved?",
        "state": "open",
        "created_at": "2025-07-16T03:11:40Z",
        "labels": [
          "performance"
        ],
        "errors": []
      },
      {
        "number": 20895,
        "title": "[Bug]: Gemma3 can not be launched in vllm CLI",
        "state": "closed",
        "created_at": "2025-07-14T02:37:03Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "message is arranged at the end (i can not findout the issue for reviewing the error message though).",
          "message : "
        ]
      },
      {
        "number": 20860,
        "title": "[Bug]: Ray + vLLM failing to automatically release GPU memory when tensor parallelism size (tp_size) > 1",
        "state": "open",
        "created_at": "2025-07-12T11:11:25Z",
        "labels": [
          "bug",
          "ray"
        ],
        "errors": [
          "s, \u200b\u200bbut it fails to automatically release GPU memory after completion\u200b\u200b.",
          "s, \u200b\u200bbut it fails to automatically release GPU memory after completion\u200b\u200b."
        ]
      },
      {
        "number": 20743,
        "title": "[Bug]: Intel Arc 140T GPU XPU backend fails with \"doesn't support querying the available free memory\" error",
        "state": "open",
        "created_at": "2025-07-10T07:38:57Z",
        "labels": [
          "bug"
        ],
        "errors": [
          "occurs during KV cache initialization when vLLM attempts to query available GPU memory using `torch.xpu.mem_get_info()`, which is not supported on Intel Arc GPUs.",
          "message"
        ]
      }
    ]
  }
}